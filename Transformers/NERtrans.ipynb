{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f720983",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-28 15:43:41.382852: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-06-28 15:43:41.384376: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-06-28 15:43:41.414303: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-06-28 15:43:41.415176: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-28 15:43:42.026285: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import BertTokenizerFast, BertForTokenClassification\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import SGD\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1843265b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence#</th>\n",
       "      <th>text</th>\n",
       "      <th>POStags</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>' ಆವಿಷ್ಕಾರ , ಸುಸ್ಥಿರತೆ ಮತ್ತು ಬಹುಪಕ್ಷೀಯ ಸಹಕಾರ '...</td>\n",
       "      <td>RD_PUNC N_NN RD_PUNC N_NN CC_CCD JJ N_NN RD_PU...</td>\n",
       "      <td>O O O O O O O O O O NEL O NEL O O O NETE NETE O O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>ಮಾರ್ಚ್ 16 , 2022 .</td>\n",
       "      <td>N_NNP QT_QTC RD_PUNC QT_QTC RD_PUNC</td>\n",
       "      <td>NED NED O NEN O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>ಮಹಾಮಹಿಮ ಶ್ರೀ ಫ್ರಾಂಕೋಯಿಸ್ ಡೆಲಾಟ್ರೆ , ಪ್ರಧಾನ ಕಾರ...</td>\n",
       "      <td>N_NN N_NN N_NNP N_NNP RD_PUNC JJ N_NN RD_PUNC ...</td>\n",
       "      <td>O O NEP NEP O O O O NEL O NEL O O O O O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>ಮಹಾಮಹಿಮ ಶ್ರೀ ಇಮ್ಯಾನುಯೆಲ್ ಲೆನಿನ್ , ಭಾರತದಲ್ಲಿ ಫ್...</td>\n",
       "      <td>N_NN N_NN N_NNP N_NNP RD_PUNC N_NNP N_NNP PSP ...</td>\n",
       "      <td>O O NEP NEP O NEL NEL O O O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>ಶ್ರೀ ಜಾವೇದ್ ಅಶ್ರಫ್ , ಫ್ರಾನ್ಸ್ ಮತ್ತು ಮೊನಾಕೊದಲ್ಲ...</td>\n",
       "      <td>N_NN N_NNP N_NNP RD_PUNC N_NNP CC_CCD N_NNP N_...</td>\n",
       "      <td>O NEP NEP O NEL O NEL NEL O O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>ರಾಯಭಾರಿ ರಾಜೀವ್ ಭಾಟಿಯಾ , ಗಣ್ಯ ವ್ಯಕ್ತಿ , ಗೇಟ್‌ವೇ...</td>\n",
       "      <td>N_NNP N_NNP N_NNP RD_PUNC N_NN N_NN RD_PUNC N_...</td>\n",
       "      <td>O NEP NEP O O O O NEO NEO O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>ಮಹಿಳೆಯರೇ ಮತ್ತು ಮಹನೀಯರೇ ಹಾಗೂ ವಿಶೇಷ ಭಾಗೀದಾರರೇ ,</td>\n",
       "      <td>N_NN CC_CCD N_NN CC_CCD JJ N_NN RD_PUNC</td>\n",
       "      <td>O O O O O O O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>ನಮಸ್ಕಾರ .</td>\n",
       "      <td>N_NN RD_PUNC</td>\n",
       "      <td>O O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>ಇಂದು ಭಾರತ - ಫ್ರಾನ್ಸ್ ಟ್ರ್ಯಾಕ್ 1.5 ನೇ ಸಂವಾದದಲ್ಲ...</td>\n",
       "      <td>N_NN N_NNP RD_SYM N_NNP N_NNP QT_QTC N_NN N_NN...</td>\n",
       "      <td>O NEL O NEL O NEN O O O O O O O O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>ಜಾಗತಿಕ ಥಿಂಕ್ - ಟ್ಯಾಂಕ್ ಸ್ಪೇಸ್ ನ ಎರಡು ಅತ್ಯಂತ ಸಕ...</td>\n",
       "      <td>JJ N_NN RD_SYM N_NN N_NN PSP QT_QTC RP_INTF JJ...</td>\n",
       "      <td>O O O O O O O O O O O NEO NEO O NEO O O O O O O O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>2 .ಅಕ್ಟೋಬರ್ 2020 ರಲ್ಲಿ ನಾನು ಪ್ಯಾರಿಸ್‌ಗೆ ಭೇಟಿ ನ...</td>\n",
       "      <td>QT_QTC N_NNP QT_QTC PSP PR_PRP N_NNP N_NN V_VM...</td>\n",
       "      <td>NED NED NED O O NEL O O O NEO O O O O O O O O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sentence#                                               text  \\\n",
       "0           1  ' ಆವಿಷ್ಕಾರ , ಸುಸ್ಥಿರತೆ ಮತ್ತು ಬಹುಪಕ್ಷೀಯ ಸಹಕಾರ '...   \n",
       "1           2                                 ಮಾರ್ಚ್ 16 , 2022 .   \n",
       "2           3  ಮಹಾಮಹಿಮ ಶ್ರೀ ಫ್ರಾಂಕೋಯಿಸ್ ಡೆಲಾಟ್ರೆ , ಪ್ರಧಾನ ಕಾರ...   \n",
       "3           4  ಮಹಾಮಹಿಮ ಶ್ರೀ ಇಮ್ಯಾನುಯೆಲ್ ಲೆನಿನ್ , ಭಾರತದಲ್ಲಿ ಫ್...   \n",
       "4           5  ಶ್ರೀ ಜಾವೇದ್ ಅಶ್ರಫ್ , ಫ್ರಾನ್ಸ್ ಮತ್ತು ಮೊನಾಕೊದಲ್ಲ...   \n",
       "5           6  ರಾಯಭಾರಿ ರಾಜೀವ್ ಭಾಟಿಯಾ , ಗಣ್ಯ ವ್ಯಕ್ತಿ , ಗೇಟ್‌ವೇ...   \n",
       "6           7      ಮಹಿಳೆಯರೇ ಮತ್ತು ಮಹನೀಯರೇ ಹಾಗೂ ವಿಶೇಷ ಭಾಗೀದಾರರೇ ,   \n",
       "7           8                                          ನಮಸ್ಕಾರ .   \n",
       "8           9  ಇಂದು ಭಾರತ - ಫ್ರಾನ್ಸ್ ಟ್ರ್ಯಾಕ್ 1.5 ನೇ ಸಂವಾದದಲ್ಲ...   \n",
       "9          10  ಜಾಗತಿಕ ಥಿಂಕ್ - ಟ್ಯಾಂಕ್ ಸ್ಪೇಸ್ ನ ಎರಡು ಅತ್ಯಂತ ಸಕ...   \n",
       "10         11  2 .ಅಕ್ಟೋಬರ್ 2020 ರಲ್ಲಿ ನಾನು ಪ್ಯಾರಿಸ್‌ಗೆ ಭೇಟಿ ನ...   \n",
       "\n",
       "                                              POStags  \\\n",
       "0   RD_PUNC N_NN RD_PUNC N_NN CC_CCD JJ N_NN RD_PU...   \n",
       "1                 N_NNP QT_QTC RD_PUNC QT_QTC RD_PUNC   \n",
       "2   N_NN N_NN N_NNP N_NNP RD_PUNC JJ N_NN RD_PUNC ...   \n",
       "3   N_NN N_NN N_NNP N_NNP RD_PUNC N_NNP N_NNP PSP ...   \n",
       "4   N_NN N_NNP N_NNP RD_PUNC N_NNP CC_CCD N_NNP N_...   \n",
       "5   N_NNP N_NNP N_NNP RD_PUNC N_NN N_NN RD_PUNC N_...   \n",
       "6             N_NN CC_CCD N_NN CC_CCD JJ N_NN RD_PUNC   \n",
       "7                                        N_NN RD_PUNC   \n",
       "8   N_NN N_NNP RD_SYM N_NNP N_NNP QT_QTC N_NN N_NN...   \n",
       "9   JJ N_NN RD_SYM N_NN N_NN PSP QT_QTC RP_INTF JJ...   \n",
       "10  QT_QTC N_NNP QT_QTC PSP PR_PRP N_NNP N_NN V_VM...   \n",
       "\n",
       "                                               labels  \n",
       "0   O O O O O O O O O O NEL O NEL O O O NETE NETE O O  \n",
       "1                                     NED NED O NEN O  \n",
       "2             O O NEP NEP O O O O NEL O NEL O O O O O  \n",
       "3                         O O NEP NEP O NEL NEL O O O  \n",
       "4                       O NEP NEP O NEL O NEL NEL O O  \n",
       "5                         O NEP NEP O O O O NEO NEO O  \n",
       "6                                       O O O O O O O  \n",
       "7                                                 O O  \n",
       "8                   O NEL O NEL O NEN O O O O O O O O  \n",
       "9   O O O O O O O O O O O NEO NEO O NEO O O O O O O O  \n",
       "10      NED NED NED O O NEL O O O NEO O O O O O O O O  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read the dataset and rename columns\n",
    "data = pd.read_csv(\"/home/shriya/Documents/NER/Transformer/dataset.csv\")\n",
    "\n",
    "data.rename(columns={\"Sentence#\":\"sentence#\",\"Sentence\":\"text\" ,\"POS\":\"POStags\",\"Tag\":\"labels\"}, inplace=True)\n",
    "data.head(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f32b997a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-multilingual-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f10e6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_all_tokens = False\n",
    "def align_label(texts,labels):\n",
    "    tokenized_inputs = tokenizer(texts, padding='max_length', max_length=512, truncation=True)\n",
    "    word_ids = tokenized_inputs.word_ids()\n",
    "    previous_word_idx = None\n",
    "    label_ids = []\n",
    "    for word_idx in word_ids:\n",
    "        if word_idx is None:\n",
    "            label_ids.append(-100)\n",
    "        elif word_idx != previous_word_idx:\n",
    "            try:\n",
    "                label_ids.append(labels_to_ids[labels[word_idx]])\n",
    "            except:\n",
    "                label_ids.append(-100)\n",
    "        else:\n",
    "            try:\n",
    "                label_ids.append(labels_to_ids[labels[word_idx]] if label_all_tokens else -100)\n",
    "            except:\n",
    "                label_ids.append(-100)\n",
    "    \n",
    "        previous_word_ids = word_idx\n",
    "    return label_ids\n",
    "\n",
    "class DataSequence(torch.utils.data.Dataset):\n",
    "    def __init__(self, data):\n",
    "        \n",
    "        lb = [i.split() for i in data[\"labels\"].values.tolist()]\n",
    "        txt = data[\"text\"].values.tolist()\n",
    "        self.texts = [tokenizer(str(i), padding=\"max_length\", max_length=512,\n",
    "                               truncation=True, return_tensors=\"pt\") for i in txt]\n",
    "        self.labels = [align_label(i,j) for i,j in zip(txt,lb)]\n",
    "        \n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.labels)\n",
    "    \n",
    "    def get_batch_data(self,idx):\n",
    "        return self.texts[idx]\n",
    "    \n",
    "    def get_batch_labels(self, idx):\n",
    "        return torch.LongTensor(self.labels[idx])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        batch_data = self.get_batch_data(idx)\n",
    "        batch_labels = self.get_batch_labels(idx)\n",
    "        return batch_data , batch_labels\n",
    "        \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14db7aa4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'text = data[\\'text\\'].values.tolist()\\nexample = text[10]\\nl = data[\\'labels\\'].values.tolist()\\nlabel = l[10]\\n#print sentence\\nprint(example)\\ntokenized_inputs = tokenizer(example, padding=\\'max_length\\', max_length=512, truncation=True)\\n#prints input_ids, token_type_ids, attention_mask\\nprint(tokenized_inputs)\\n#decode ids back to original sentence\\nprint(tokenizer.decode(tokenized_inputs.input_ids))\\n#all words of sentence hv the same word_id\\nword_ids = tokenized_inputs.word_ids()\\nprint(tokenizer.convert_ids_to_tokens(tokenized_inputs[\"input_ids\"]))\\nprint(word_ids)\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''text = data['text'].values.tolist()\n",
    "example = text[10]\n",
    "l = data['labels'].values.tolist()\n",
    "label = l[10]\n",
    "#print sentence\n",
    "print(example)\n",
    "tokenized_inputs = tokenizer(example, padding='max_length', max_length=512, truncation=True)\n",
    "#prints input_ids, token_type_ids, attention_mask\n",
    "print(tokenized_inputs)\n",
    "#decode ids back to original sentence\n",
    "print(tokenizer.decode(tokenized_inputs.input_ids))\n",
    "#all words of sentence hv the same word_id\n",
    "word_ids = tokenized_inputs.word_ids()\n",
    "print(tokenizer.convert_ids_to_tokens(tokenized_inputs[\"input_ids\"]))\n",
    "print(word_ids)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "910e3d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'NEA', 'NETE', 'O', 'NEO', 'NEN', 'NEP', 'NED', 'NEL'}\n",
      "{'NEA': 0, 'NETE': 1, 'O': 2, 'NEO': 3, 'NEN': 4, 'NEP': 5, 'NED': 6, 'NEL': 7}\n"
     ]
    }
   ],
   "source": [
    "#find the unique labels give them an index\n",
    "\n",
    "labels = [i.split() for i in data['labels'].values.tolist()]\n",
    "unique_labels = set()\n",
    "\n",
    "for lb in labels:\n",
    "    [unique_labels.add(i) for i in lb if i not in unique_labels]\n",
    "    \n",
    "labels_to_ids = {k: v for v, k in enumerate(unique_labels)}\n",
    "ids_to_labels = {v: k for v, k in enumerate(unique_labels)}\n",
    "\n",
    "data_train,data_val, data_test = np.split(data.sample(frac=1, random_state = 42),\n",
    "                                         [int(.8*len(data)),int(.9*len(data))])\n",
    "\n",
    "print(unique_labels)\n",
    "print(labels_to_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "738f3019",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BertModel, self).__init__()\n",
    "        self.bert = BertForTokenClassification.from_pretrained('bert-base-multilingual-uncased', num_labels=len(unique_labels))\n",
    "    \n",
    "    def forward(self, input_id, mask, label):\n",
    "        output = self.bert(input_ids=input_id, attention_mask=mask, labels=label, return_dict=False)\n",
    "        return output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6e20868",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  0%|          | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:59<00:00,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:59<00:00,  2.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Epochs: 1 | Loss:  0.917 | Accuracy:  0.751 | Val_Loss:  0.498 | Accuracy:  0.890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [01:11<00:00,  3.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [01:11<00:00,  3.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Epochs: 2 | Loss:  0.627 | Accuracy:  0.815 | Val_Loss:  0.490 | Accuracy:  0.880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [01:13<00:00,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [01:14<00:00,  3.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Epochs: 3 | Loss:  0.528 | Accuracy:  0.849 | Val_Loss:  0.555 | Accuracy:  0.858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [01:10<00:00,  2.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [01:10<00:00,  2.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Epochs: 4 | Loss:  0.462 | Accuracy:  0.860 | Val_Loss:  0.552 | Accuracy:  0.874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [01:12<00:00,  3.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Epochs: 5 | Loss:  0.463 | Accuracy:  0.863 | Val_Loss:  0.562 | Accuracy:  0.870\n"
     ]
    }
   ],
   "source": [
    "def train_loop(model, data_train, data_val):\n",
    "\n",
    "    train_dataset = DataSequence(data_train)\n",
    "    val_dataset = DataSequence(data_val)\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset, num_workers=4, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_dataloader = DataLoader(val_dataset, num_workers=4, batch_size=BATCH_SIZE)\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    optimizer = SGD(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "    if use_cuda:\n",
    "        model = model.cuda()\n",
    "\n",
    "    best_acc = 0\n",
    "    best_loss = 1000\n",
    "\n",
    "    for epoch_num in range(EPOCHS):\n",
    "\n",
    "        total_acc_train = 0\n",
    "        total_loss_train = 0\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        for train_data, train_label in tqdm(train_dataloader):\n",
    "\n",
    "            train_label = train_label.to(device)\n",
    "            mask = train_data['attention_mask'].squeeze(1).to(device)\n",
    "            input_id = train_data['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss, logits = model(input_id, mask, train_label)\n",
    "\n",
    "            for i in range(logits.shape[0]):\n",
    "\n",
    "              logits_clean = logits[i][train_label[i] != -100]\n",
    "              label_clean = train_label[i][train_label[i] != -100]\n",
    "\n",
    "              predictions = logits_clean.argmax(dim=1)\n",
    "              acc = (predictions == label_clean).float().mean()\n",
    "              total_acc_train += acc\n",
    "              total_loss_train += loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        total_acc_val = 0\n",
    "        total_loss_val = 0\n",
    "\n",
    "        for val_data, val_label in val_dataloader:\n",
    "\n",
    "            val_label = val_label.to(device)\n",
    "            mask = val_data['attention_mask'].squeeze(1).to(device)\n",
    "            input_id = val_data['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "            loss, logits = model(input_id, mask, val_label)\n",
    "\n",
    "            for i in range(logits.shape[0]):\n",
    "\n",
    "              logits_clean = logits[i][val_label[i] != -100]\n",
    "              label_clean = val_label[i][val_label[i] != -100]\n",
    "\n",
    "              predictions = logits_clean.argmax(dim=1)\n",
    "              acc = (predictions == label_clean).float().mean()\n",
    "              total_acc_val += acc\n",
    "              total_loss_val += loss.item()\n",
    "\n",
    "        val_accuracy = total_acc_val / len(data_val)\n",
    "        val_loss = total_loss_val / len(data_val)\n",
    "\n",
    "        print(\n",
    "            f'Epochs: {epoch_num + 1} | Loss: {total_loss_train / len(data_train): .3f} | Accuracy: {total_acc_train / len(data_train): .3f} | Val_Loss: {total_loss_val / len(data_val): .3f} | Accuracy: {total_acc_val / len(data_val): .3f}')\n",
    "\n",
    "LEARNING_RATE = 5e-3\n",
    "EPOCHS = 5\n",
    "BATCH_SIZE = 2\n",
    "\n",
    "model = BertModel()\n",
    "train_loop(model, data_train, data_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4d000c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Test Accuracy:  0.911\n",
      "Loss:  0.405\n"
     ]
    }
   ],
   "source": [
    "def evaluate(model, data_test):\n",
    "\n",
    "    test_dataset = DataSequence(data_test)\n",
    "\n",
    "    test_dataloader = DataLoader(test_dataset, num_workers=4, batch_size=1)\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    if use_cuda:\n",
    "        model = model.cuda()\n",
    "\n",
    "    total_acc_test = 0\n",
    "    total_loss_test = 0\n",
    "    \n",
    "    for test_data, test_label in test_dataloader:\n",
    "\n",
    "            test_label = test_label.to(device)\n",
    "            mask = test_data['attention_mask'].squeeze(1).to(device)\n",
    "\n",
    "            input_id = test_data['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "            loss, logits = model(input_id, mask, test_label)\n",
    "\n",
    "            for i in range(logits.shape[0]):\n",
    "\n",
    "              logits_clean = logits[i][test_label[i] != -100]\n",
    "              label_clean = test_label[i][test_label[i] != -100]\n",
    "\n",
    "              predictions = logits_clean.argmax(dim=1)\n",
    "              acc = (predictions == label_clean).float().mean()\n",
    "              total_acc_test += acc\n",
    "              total_loss_test += loss.item()\n",
    "            \n",
    "\n",
    "    val_accuracy = total_acc_test / len(data_test)\n",
    "    print(f'Test Accuracy: {total_acc_test / len(data_test): .3f}')\n",
    "    print(f'Loss: {total_loss_test / len(data_test): .3f}')\n",
    "\n",
    "\n",
    "evaluate(model, data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4bdf6d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_word_ids(texts):\n",
    "  \n",
    "    tokenized_inputs = tokenizer(texts, padding='max_length', max_length=512, truncation=True)\n",
    "\n",
    "    word_ids = tokenized_inputs.word_ids()\n",
    "\n",
    "    previous_word_idx = None\n",
    "    label_ids = []\n",
    "\n",
    "    for word_idx in word_ids:\n",
    "\n",
    "        if word_idx is None:\n",
    "            label_ids.append(-100)\n",
    "\n",
    "        elif word_idx != previous_word_idx:\n",
    "            try:\n",
    "                label_ids.append(1)\n",
    "            except:\n",
    "                label_ids.append(-100)\n",
    "        else:\n",
    "            try:\n",
    "                label_ids.append(1 if label_all_tokens else -100)\n",
    "            except:\n",
    "                label_ids.append(-100)\n",
    "        previous_word_idx = word_idx\n",
    "\n",
    "    return label_ids\n",
    "\n",
    "\n",
    "def evaluate_one_text(model, sentence):\n",
    "\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    if use_cuda:\n",
    "        model = model.cuda()\n",
    "\n",
    "    text = tokenizer(sentence, padding='max_length', max_length = 512, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "    mask = text['attention_mask'].to(device)\n",
    "    input_id = text['input_ids'].to(device)\n",
    "    label_ids = torch.Tensor(align_word_ids(sentence)).unsqueeze(0).to(device)\n",
    "\n",
    "    logits = model(input_id, mask, None)\n",
    "    logits_clean = logits[0][label_ids != -100]\n",
    "\n",
    "    predictions = logits_clean.argmax(dim=1).tolist()\n",
    "    prediction_label = [ids_to_labels[i] for i in predictions]\n",
    "    print(sentence)\n",
    "    print(prediction_label)\n",
    "            \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12636bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ಭಾರತವು ಒಂದು ದೇಶವಾಗಿದೆ.\n",
      "['NEL', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "evaluate_one_text(model, 'ಭಾರತವು ಒಂದು ದೇಶವಾಗಿದೆ.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226d0755",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
